(window.webpackJsonp=window.webpackJsonp||[]).push([[164],{783:function(t,s,n){"use strict";n.r(s);var a=n(15),p=Object(a.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"pandas-概述"}},[t._v("pandas 概述")]),t._v(" "),n("ul",[n("li",[t._v("2020.06.21")])]),t._v(" "),n("ol",[n("li",[t._v("Pandas是Python的一个数据分析包，该工具为解决数据分析任务而创建。")]),t._v(" "),n("li",[t._v("Pandas纳入大量库和标准数据模型，提供高效的操作数据集所需的工具。")]),t._v(" "),n("li",[t._v("Pandas提供大量能使我们快速便捷地处理数据的函数和方法。")]),t._v(" "),n("li",[t._v("Pandas是字典形式，基于NumPy创建，让NumPy为中心的应用变得更加简单。")])]),t._v(" "),n("p",[t._v("通常的引用形式是以下约定俗成的方式:")]),t._v(" "),n("div",{staticClass:"language-py extra-class"},[n("pre",{pre:!0,attrs:{class:"language-py"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n")])])]),n("h2",{attrs:{id:"数据结构"}},[t._v("数据结构")]),t._v(" "),n("p",[t._v("Pandas有三个主要数据结构"),n("code",[t._v("Series（一维")]),t._v("）和"),n("code",[t._v("DataFrame（二维）")]),t._v("以及"),n("code",[t._v("Panel(三维或可变维数据)")])]),t._v(" "),n("ul",[n("li",[n("h3",{attrs:{id:"series"}},[t._v("Series")])])]),t._v(" "),n("blockquote",[n("p",[n("code",[t._v("series")]),t._v("本质上是一个含有索引的一维数组,看起来其包含一个左侧可以自动生成(也可以手动指定)的"),n("code",[t._v("index")]),t._v("和右侧的"),n("code",[t._v("value")]),t._v("值。分别使用"),n("code",[t._v("s.index")]),t._v("和"),n("code",[t._v("s.values")]),t._v("进行查看。"),n("code",[t._v("index")]),t._v("返回一个"),n("code",[t._v("index对象")]),t._v(",而"),n("code",[t._v("values")]),t._v("返回一个"),n("code",[t._v("array")]),t._v("。")])]),t._v(" "),n("div",{staticClass:"language-py extra-class"},[n("pre",{pre:!0,attrs:{class:"language-py"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n\ns"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("pd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Series"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("nan"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("s"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#索引在左边 值在右边")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n    0    1.0\n    1    2.0\n    2    3.0\n    3    NaN\n    4    5.0\n    5    6.0\n    dtype: float64\n'''")]),t._v("\n")])])]),n("ul",[n("li",[t._v("DataFrame")])]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" numpy "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" np\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pandas "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" pd\n\ndates"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("pd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("date_range"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'20180310'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("periods"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 生成6行4列位置")]),t._v("\ndf "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("randn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" index"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("dates"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" columns"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'C'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 输出6行4列的表格")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n                A         B         C         D\n2018-03-10 -0.092889 -0.503172  0.692763 -1.261313\n2018-03-11 -0.895628 -2.300249 -1.098069  0.468986\n2018-03-12  0.084732 -1.275078  1.638007 -0.291145\n2018-03-13 -0.561528  0.431088  0.430414  1.065939\n2018-03-14  1.485434 -0.341404  0.267613 -1.493366\n2018-03-15 -1.671474  0.110933  1.688264 -0.910599\n  '''")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n2018-03-10   -0.927291\n2018-03-11   -0.406842\n2018-03-12   -0.088316\n2018-03-13   -1.631055\n2018-03-14   -0.929926\n2018-03-15   -0.010904\nFreq: D, Name: B, dtype: float64\n '''")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#创建特定数据的DataFrame")]),t._v("\ndf_1"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("pd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'A'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'B'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Timestamp"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'20180310'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'C'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Series"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("index"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("dtype"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'float32'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'D'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" np"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("dtype"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'int32'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'E'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pd"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Categorical"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"test"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"train"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"test"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"train"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'F'")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'foo'")]),t._v("\n                    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n     A          B    C  D      E    F\n0  1.0 2018-03-10  1.0  3   test  foo\n1  1.0 2018-03-10  1.0  3  train  foo\n2  1.0 2018-03-10  1.0  3   test  foo\n3  1.0 2018-03-10  1.0  3  train  foo\n'''")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dtypes"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\nA           float64\nB    datetime64[ns]\nC           float32\nD             int32\nE          category\nF            object\ndtype: object\n'''")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("index"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#行的序号")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#Int64Index([0, 1, 2, 3], dtype='int64')")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("columns"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#列的序号名字")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#Index(['A', 'B', 'C', 'D', 'E', 'F'], dtype='object')")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("values"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#把每个值进行打印出来")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n[[1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'test' 'foo']\n [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'train' 'foo']\n [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'test' 'foo']\n [1.0 Timestamp('2018-03-10 00:00:00') 1.0 3 'train' 'foo']]\n '''")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("describe"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#数字总结")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n         A    C    D\ncount  4.0  4.0  4.0\nmean   1.0  1.0  3.0\nstd    0.0  0.0  0.0\nmin    1.0  1.0  3.0\n25%    1.0  1.0  3.0\n50%    1.0  1.0  3.0\n75%    1.0  1.0  3.0\nmax    1.0  1.0  3.0\n'''")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("T"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#翻转数据")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n                     0                    1                    2  \\\nA                    1                    1                    1   \nB  2018-03-10 00:00:00  2018-03-10 00:00:00  2018-03-10 00:00:00   \nC                    1                    1                    1   \nD                    3                    3                    3   \nE                 test                train                 test   \nF                  foo                  foo                  foo   \n\n                     3  \nA                    1  \nB  2018-03-10 00:00:00  \nC                    1  \nD                    3  \nE                train  \nF                  foo  \n'''")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sort_index"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("axis"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ascending"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#axis等于1按列进行排序 如ABCDEFG 然后ascending倒叙进行显示")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n     F      E  D    C          B    A\n0  foo   test  3  1.0 2018-03-10  1.0\n1  foo  train  3  1.0 2018-03-10  1.0\n2  foo   test  3  1.0 2018-03-10  1.0\n3  foo  train  3  1.0 2018-03-10  1.0\n'''")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df_1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sort_values"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("by"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'E'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#按值进行排序")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("'''\n     A          B    C  D      E    F\n0  1.0 2018-03-10  1.0  3   test  foo\n2  1.0 2018-03-10  1.0  3   test  foo\n1  1.0 2018-03-10  1.0  3  train  foo\n3  1.0 2018-03-10  1.0  3  train  foo\n'''")]),t._v("\n\n")])])])])}),[],!1,null,null,null);s.default=p.exports}}]);